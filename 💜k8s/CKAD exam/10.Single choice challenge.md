- what happens when you apply both container and pod level security context settings that overlap?

The container level security context settings override settings made at the pod level


Explanation
Container level security context settings are applied to the specific container and override settings made at the pod level where there is overlap. Container level settings however do not affect the pod’s volumes.

Learn more: https://kubernetes.io/docs/concepts/policy/security-context/


---

- record or store client library information that is useful for debugging purposes, like name, version, and build info. 

Assign adequate annotations.


Explanation
Annotations are useful to be able to attach arbitrary non-identifying metadata, for retrieval by API clients such as tools, libraries, etc. This information may be large, may be structured or unstructured, may include characters not permitted by labels, etc. Such information would not be used for object selection and therefore doesn’t belong in labels.

Examples of such information include:

fields managed by a declarative configuration layer, to distinguish them from client- and/or server-set default values and other auto-generated fields, fields set by auto-sizing/auto-scaling systems, etc., in order to facilitate merging
build/release/image information (timestamps, release ids, git branch, PR numbers, image hashes, registry address, etc.)
pointers to logging/monitoring/analytics/audit repos
client library/tool information (e.g. for debugging purposes – name, version, build info)
other user and/or tool/system provenance info, such as URLs of related objects from other ecosystem components
lightweight rollout tool metadata (config and/or checkpoints)
phone/pager number(s) of person(s) responsible, or directory entry where that info could be found, such as a team website


Learn more: https://kubernetes.io/docs/user-guide/annotations/


--

- create a service account named jenkins

`kubectl create serviceaccount jenkins`

Explanation
Service account bearer tokens are perfectly valid to use outside the cluster and can be used to create identities for long standing jobs that wish to talk to the Kubernetes API. To manually create a service account, simply use the kubectl create serviceaccount (NAME)command. This creates a service account in the current namespace and an associated secret. For example:
$ kubectl create serviceaccount jenkins

Learn more: https://kubernetes.io/docs/reference/access-authn-authz/authentication/


---

- first step when debugging a pod?

Use the "kubectl describe pods" and "kubectl logs" commands to check the current state of the pod and recent events.

Explanation
The first step in debugging a pod is taking a look at it. Check the current state of the pod and recent events with the following command:

$ kubectl describe pods ${POD_NAME}
Look at the state of the containers in the pod. Are they all Running? Have there been recent restarts?

Continue debugging depending on the state of the pods.


Learn more: https://kubernetes.io/docs/tasks/debug/debug-application/debug-pods/


---

-  to start sending traffic to a pod only when a probe succeeds. What is the best type of probe in this situation?

Use a ReadinessProbe and a RestartPolicy of Always or OnFailure.

Explanation
If the process in your container is able to crash on its own whenever it encounters an issue or becomes unhealthy, you do not necessarily need a liveness probe; the kubelet will automatically perform the correct action in accordance with the RestartPolicy when the process crashes.
If you’d like your container to be killed and restarted if a probe fails, then specify a LivenessProbe and a RestartPolicy of Always or OnFailure.
If you’d like to start sending traffic to a pod only when a probe succeeds, specify a ReadinessProbe. In this case, the ReadinessProbe may be the same as the LivenessProbe, but the existence of the ReadinessProbe in the spec means that the pod will start without receiving any traffic and only start receiving traffic once the probe starts succeeding.
If a container wants the ability to take itself down for maintenance, you can specify a ReadinessProbe that checks an endpoint specific to readiness, which is different than the LivenessProbe.

Learn more: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/


---

Containers within a pod share an IP address and port space, and can find each other via localhost.


Explanation
Containers within a pod share an IP address and port space, and can find each other via the localhost. They can also communicate with each other using standard inter-process communications like SystemV semaphores or POSIX shared memory. Containers in different pods have distinct IP addresses and cannot communicate by IPC.


Learn more: https://kubernetes.io/docs/concepts/workloads/pods/

---

Explanation
Containers within a pod share an IP address and port space, and can find each other via the localhost. They can also communicate with each other using standard inter-process communications like SystemV semaphores or POSIX shared memory. Containers in different pods have distinct IP addresses and cannot communicate by IPC.


Learn more: https://kubernetes.io/docs/concepts/workloads/pods/



---


- using pods to co-locate a content management system with a data loader and a local cache manager. A new team member suggests running these programs in a single Docker container instead. You explain to him that Kubernetes recommend using pods because it


allows individual containers to be versioned, rebuilt, and redeployed independently

Explanation
Running multiple programs in a single (Docker) container is not recommended for the reasons below.

Transparency: Making the containers within the pod visible to the infrastructure enables the infrastructure to provide services to those containers, such as process management and resource monitoring. This facilitates a number of conveniences for users.
Decoupling software dependencies: The individual containers may be versioned, rebuilt and redeployed independently. Kubernetes may even support live updates of individual containers someday.
Ease of use: Users don’t need to run their own process managers, worry about signal and exit-code propagation, etc.
Efficiency: Because the infrastructure takes on more responsibility, containers can be lighter weight.
Affinity-based co-scheduling of containers is also not recommended because although this approach would provide co-location, it would not provide most of the benefits of pods, such as resource sharing, IPC, guaranteed fate sharing, and simplified management.


Learn more: https://kubernetes.io/docs/concepts/workloads/pods/

---


- A Kubernetes ____ is an abstraction that defines a logical set of Pods and a policy by which to access them.

Service


---

- What is one scenario in which the use of Kubernetes pods would be recommended?

To support co-located, co-managed helper programs


Explanation
Pods can be used to host vertically integrated application stacks (e.g., LAMP), but their primary motivation is to support co-located, co-managed helper programs, such as:

content management systems, file and data loaders, local cache managers, etc.
log and checkpoint backup, compression, rotation, snapshotting, etc.
data change watchers, log tailers, logging and monitoring adapters, event publishers, etc.
proxies, bridges, and adapters
controllers, managers, configurators, and updaters
Individual pods are not intended to run multiple instances of the same application, in general.


Learn more: https://kubernetes.io/docs/user-guide/pods/

---

- Service accounts are tied to a set of credentials stored as ____, which are mounted into pods allowing in cluster processes to talk to the Kubernetes API.

Secrets

Explanation
Service accounts are users managed by the Kubernetes API and are bound to specific namespaces. The accounts are created automatically by the API server or manually through API calls, and tied to a set of credentials stored as Secrets. These Secrets are then mounted into pods allowing in cluster processes to talk to the Kubernetes API.

Bookmark
Learn more: https://kubernetes.io/docs/reference/access-authn-authz/authentication/


---


- How would you segment resources in Kubernetes when you want to prevent users from easily affecting resources in other projects, teams, or environments?

Create a Namespace for each segment


Explanation
You can use labels to distinguish resources within the same Namespace. However, to avoid unintentionally modifying other teams' resources, you are better off using Namespaces. Namespaces provide a scope for names. Names of resources need to be unique within a Namespace, but not across Namespaces. This reduces the chance of unitentionally affecting other teams' resources.


Learn more: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/

---

- set-based label selector that filters resources with a partition key (no matter the value) and with environment different than qa. Write a set-based label selector that accomplishes this task.

partition, environment notin (qa)


Explanation

Set-based label requirements allow filtering keys according to a set of values. Three kinds of operators are supported: in,notin and exists (only the key identifier). The comma separator acts as an AND operator. So filtering resources with a partition key (no matter the value) and with environment different than qa can be achieved using partition,environment notin (qa). The set-based label selector is a general form of equality since environment=production is equivalent to environment in (production); similarly for != and notin


Learn more: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/


---

- You have created a service for two nginx replicas using the kubectl create -f command, with the following yaml:
```yaml
nginx-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-nginx
  labels:
    run: my-nginx
spec:
  ports:
  - port: 80
    protocol: TCP
  selector:
    run: my-nginx
```
What is another approach you could take to accomplish the same result? (Assume that you have already created a deployment named "my-nginx" with these specifications.)

`kubectl expose deployment my-nginx`

---

- to utilize a PersistentVolume for application storage in a Kubernetes cluster. What field of a PersistentVolume can you use to control the number of nodes that can mount the PersistentVolume for reading and writing?

accessMode

Explanation
A PersistentVolumes accessMode field controls how many nodes can mount it for reading and writing. The supported values are ReadWriteOnce, ReadOnlyMany, and ReadWriteMany.

Bookmark
Learn more: /lab/deploy-a-stateful-application-in-a-kubernetes-cluster/deploying-stateful-application-kubernetes-cluster/

---


-  why is it recommended that you use labels?

To enable users to map their own organizational structures onto system objects in a loosely coupled fashion, without requiring clients to store these mappings.



Labels enable users to map their own organizational structures onto system objects in a loosely coupled fashion, without requiring clients to store these mappings.

Service deployments and batch processing pipelines are often multi-dimensional entities (e.g., multiple partitions or deployments, multiple release tracks, multiple tiers, multiple micro-services per tier). Management often requires cross-cutting operations, which breaks encapsulation of strictly hierarchical representations, especially rigid hierarchies determined by the infrastructure rather than by users.

Learn more: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/


---

- Every namespace has a default service account resource called ____.

default


---


- one way through which users can access the Kubernetes API?

kubectl

---



- a(n) ____ is a key/value pair, intended to be used to specify identifying attributes of objects that are meaningful and relevant to users, but which do not directly imply semantics to the core system.

label

---

- core grouping primitive in Kubernetes?

Label selector



Explanation
Unlike names and UIDs, labels do not provide uniqueness, so in general, we expect many objects to carry the same label(s). The label selector is the core grouping primitive in Kubernetes, and allows the the client/user to identify a set of objects. 


Learn more: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/


---

- The application container exposes port 80. You need to be able to access the application from outside of the cluster. What Kubernetes resource should you use to meet this requirement?

service


A service provides a mechanism for accessing a logical set of pods. You can use a service of type NodePort or LoadBalancer to allow external access to an application running in Kubernetes.

A binding is used for associating a role with a user to authorize actions the user is allowed to perform.

A deployment can deploy an application in the cluster, but it can't grant external access without a service.

An endpoint is a resource that a service automatically manages to keep track of the pods that are accessible via the service.


Learn more: /lab/deploy-a-stateless-application-in-a-kubernetes-cluster/deploying-a-stateless-application-in-the-kubernetes-cluster/

---

- Which two kubectl commands are useful for collecting information about any type of resource that is active in a Kubernetes cluster? (Choose 2 answers)

get
describe


---


- debug a pod that is crashing. What command would be particularly helpful during this process?

`kubectl logs`


Explanation
What to do when a pod is crashing or otherwise unhealthy?
First, take a look at the logs of the current container:

```bash
$ kubectl logs ${POD_NAME} ${CONTAINER_NAME}
```
If your container has previously crashed, you can access the previous container’s crash log with:

```bash
$ kubectl logs --previous ${POD_NAME} ${CONTAINER_NAME}
```
Alternately, you can run commands inside that container with exec:
```bash
$ kubectl exec ${POD_NAME} -c ${CONTAINER_NAME} -- ${CMD} ${ARG1} ${ARG2} ... ${ARGN}
```

Learn more: https://kubernetes.io/docs/tasks/debug/debug-application/debug-running-pod/


---

- Service accounts within Kubernetes are associated with ____.

pods running in the clusters


Explanation
All Kubernetes clusters have two categories of users: service accounts managed by Kubernetes, and normal users.


In contrast, service accounts are users managed by the Kubernetes API. They are bound to specific namespaces, and created automatically by the API server or manually through API calls. Service accounts are tied to a set of credentials stored as Secrets, which are mounted into pods that allow cluster processes to talk to the Kubernetes API.


Learn more: https://kubernetes.io/docs/admin/authentication/

---



- to use a monitoring tool that supports Kubernetes natively. 

Metrics Server/Heapster

Explanation
Metrics Server, and its predecessor Heapster, are cluster-wide aggregator of monitoring and event data. It currently supports Kubernetes natively and works on all Kubernetes setups. Heapster and Metrics Server run as a pod in the cluster, similar to how any Kubernetes application would run. The Heapster or Metrics Server pod discovers all nodes in the cluster and queries usage information from the nodes’ Kubelet, the on-machine Kubernetes agent. The Kubelet itself fetches the data from cAdvisor. Heapster or Metrics Server groups the information by pod along with the relevant labels. This data is then pushed to a configurable backend for storage and visualization.


Learn more: https://kubernetes.io/docs/user-guide/monitoring/



---

- Which of the following statements related to Kubernetes storage are true?

A Volume's lifetime is connected to the lifetime of a pod
PersistentVolumes must be explicitly claimed by pods


Explanation
A Volume's lifetime is the same as the lifetime of the pod that encloses it. PersistentVolumes have a lifetime independent of any pod allowing the data on a PersistentVolume to be reused by other pods.

PersistentVolumes must be claimed by pods using PersistentVolumeClaims. Volumes do not require the use of claims. Simply including a volume in a Pod spec is enough to create and access the volume in the pod.

Both Volumes and PersistentVolumes can be accessed by all of the containers in the pod enclosing them.


Learn more: /course/introduction-to-kubernetes/volumes/


---


You have written a manifest file for a service in Kubernetes. You did not include the type field in the service's specification. What is the type of the service that will be created?

ClusterIP


Explanation

If you don't specify a type for a service, it will use the default value of ClusterIp. ClusterIp services are accessible only within the cluster. Other types of services can be used to access a service from outside the cluster (NodePort and LoadBalancer) or access services outside the cluster (ExternalName).


Learn more: https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/



---


The requirements dictate that the application must use an external distributed memcached service as its caching service. Which multi-container pattern would recommend they learn about to satisfy the Pod's requirements most efficiently?

Ambassador


Explanation
The application will benefit from using a proxy for accessing the distributed memcached service. Application developers only need to consider connecting to a single memcached instance running on localhost. The proxy can abstract away the complexity of sharding and multiple hosts. This is an example of the ambassador pattern. 

See the documentation URL (Design patterns for container-based distributed systems) for further details.

Bookmark
Learn more: https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45406.pdf



---



A ____ is a higher-level controller that automates rolling updates of applications declaratively.

Deployment


---



What is the recommended Kubernetes resource for running applications?


Deployment


Deployments are a high-level concept for managing applications in Kubernetes. Pods are where applications actually run, but deployments make managing applications much simpler than working with pods directly. For example, you can easily scale and perform a rolling update to a new version using deployments. 

Deployments automatically maintain a ReplicaSet for replicating pods and are easier to work with than a ReplicaSet. 

Containers aren't a type of Kubernetes resource.


Learn more: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/


--- 

- modernizing a suite of legacy applications that work together and deploying the applications as Pods in Kubernetes as part of the process. Currently the applications use several different monitoring tools and you would like to use a single monitoring tool for all the applications. You will be able to modify the code of some pieces but not others. Which multi-container Pod design pattern can you use to accomplish the goal?


Adapter



Explanation
The adapter pattern is ideally suited for this scenario. Each application can be left unmodified and the adapter can present a consistent interface to the monitoring tool. The adapter container internalizes the complexity of converting between the format of metrics each legacy application uses and single consistent interface presented to the selected monitoring tool.


Learn more: https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45406.pdf